{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "h6L_pv3uNYzw",
    "outputId": "face245f-976f-4bf2-e8a2-a3686c991a10"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import src.config as config\n",
    "from src.trainer import train_model, compute_accuracy, print_summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config.RANDOM_SEED)\n",
    "torch.manual_seed(config.RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(config.RANDOM_SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    torch.backends.cudnn.allow_tf32 = False\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "g = torch.Generator().manual_seed(config.RANDOM_SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p1njHrr5byfg"
   },
   "outputs": [],
   "source": [
    "class Roberta_Dataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    " \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "       \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "GwUKDZMw7mVU",
    "outputId": "172cc71c-02e2-46f1-d2c0-79d51d24cfdb"
   },
   "outputs": [],
   "source": [
    "class RobertaClassifier(nn.Module):  \n",
    "    def __init__(self, dropout_rate=0.3): \n",
    "        super(RobertaClassifier, self).__init__()\n",
    "\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.drop = nn.Dropout(dropout_rate)\n",
    "        self.out = nn.Linear(self.roberta.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_roberta_model(\n",
    "    x_train, y_train,\n",
    "    x_val, y_val,\n",
    "    x_test, y_test,\n",
    "    epochs=6,        \n",
    "    lr=2e-5,         \n",
    "    batch_size=32,\n",
    "    dropout_rate=0.3,\n",
    "    max_len=256,\n",
    "    patience=2,\n",
    "    device=None,\n",
    "):\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "    train_dataset = Roberta_Dataset(x_train.values, y_train.values, tokenizer, max_len)\n",
    "    val_dataset = Roberta_Dataset(x_val.values, y_val.values, tokenizer, max_len)\n",
    "    test_dataset = Roberta_Dataset(x_test.values, y_test.values, tokenizer, max_len)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = RobertaClassifier(dropout_rate=dropout_rate)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=1)\n",
    "\n",
    "\n",
    "\n",
    "    summary = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "    )\n",
    "    best_induced_test_state = summary.get(\"best_state_dict\")\n",
    "\n",
    "    print_summary(summary)\n",
    "    return summary, best_induced_test_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train = pd.read_csv(config.CLEAN_IMDB_TRAIN_PATH)\n",
    "imdb_val = pd.read_csv(config.CLEAN_IMDB_VAL_PATH)\n",
    "imdb_test = pd.read_csv(config.CLEAN_IMDB_TEST_PATH)\n",
    "\n",
    "imdb_x_train = imdb_train[config.TEXT_COL]\n",
    "imdb_y_train = imdb_train[config.LABEL_COL]\n",
    "imdb_x_val = imdb_val[config.TEXT_COL]\n",
    "imdb_y_val = imdb_val[config.LABEL_COL]\n",
    "imdb_x_test = imdb_test[config.TEXT_COL]\n",
    "imdb_y_test = imdb_test[config.LABEL_COL]\n",
    "imdb_data = {\n",
    "    \"x_train\": imdb_x_train,\n",
    "    \"y_train\": imdb_y_train,\n",
    "    \"x_val\": imdb_x_val,\n",
    "    \"y_val\": imdb_y_val,\n",
    "    \"x_test\": imdb_x_test,\n",
    "    \"y_test\": imdb_y_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 8 (no improvement for 2 epochs).\n",
      "--- Epoch History ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_31489\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_31489_level0_col0\" class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th id=\"T_31489_level0_col1\" class=\"col_heading level0 col1\" >Train Loss</th>\n",
       "      <th id=\"T_31489_level0_col2\" class=\"col_heading level0 col2\" >Train Acc</th>\n",
       "      <th id=\"T_31489_level0_col3\" class=\"col_heading level0 col3\" >Val Acc</th>\n",
       "      <th id=\"T_31489_level0_col4\" class=\"col_heading level0 col4\" >Test Acc</th>\n",
       "      <th id=\"T_31489_level0_col5\" class=\"col_heading level0 col5\" >Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_31489_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_31489_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_31489_row0_col1\" class=\"data row0 col1\" >0.4733</td>\n",
       "      <td id=\"T_31489_row0_col2\" class=\"data row0 col2\" >75.35%</td>\n",
       "      <td id=\"T_31489_row0_col3\" class=\"data row0 col3\" >92.22%</td>\n",
       "      <td id=\"T_31489_row0_col4\" class=\"data row0 col4\" >92.57%</td>\n",
       "      <td id=\"T_31489_row0_col5\" class=\"data row0 col5\" >700.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31489_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_31489_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_31489_row1_col1\" class=\"data row1 col1\" >0.2773</td>\n",
       "      <td id=\"T_31489_row1_col2\" class=\"data row1 col2\" >92.03%</td>\n",
       "      <td id=\"T_31489_row1_col3\" class=\"data row1 col3\" >93.42%</td>\n",
       "      <td id=\"T_31489_row1_col4\" class=\"data row1 col4\" >93.76%</td>\n",
       "      <td id=\"T_31489_row1_col5\" class=\"data row1 col5\" >693.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31489_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_31489_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_31489_row2_col1\" class=\"data row2 col1\" >0.2591</td>\n",
       "      <td id=\"T_31489_row2_col2\" class=\"data row2 col2\" >93.08%</td>\n",
       "      <td id=\"T_31489_row2_col3\" class=\"data row2 col3\" >93.56%</td>\n",
       "      <td id=\"T_31489_row2_col4\" class=\"data row2 col4\" >94.04%</td>\n",
       "      <td id=\"T_31489_row2_col5\" class=\"data row2 col5\" >695.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31489_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_31489_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_31489_row3_col1\" class=\"data row3 col1\" >0.2457</td>\n",
       "      <td id=\"T_31489_row3_col2\" class=\"data row3 col2\" >93.77%</td>\n",
       "      <td id=\"T_31489_row3_col3\" class=\"data row3 col3\" >93.34%</td>\n",
       "      <td id=\"T_31489_row3_col4\" class=\"data row3 col4\" >93.98%</td>\n",
       "      <td id=\"T_31489_row3_col5\" class=\"data row3 col5\" >692.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31489_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_31489_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_31489_row4_col1\" class=\"data row4 col1\" >0.2383</td>\n",
       "      <td id=\"T_31489_row4_col2\" class=\"data row4 col2\" >94.22%</td>\n",
       "      <td id=\"T_31489_row4_col3\" class=\"data row4 col3\" >93.82%</td>\n",
       "      <td id=\"T_31489_row4_col4\" class=\"data row4 col4\" >94.35%</td>\n",
       "      <td id=\"T_31489_row4_col5\" class=\"data row4 col5\" >693.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31489_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_31489_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_31489_row5_col1\" class=\"data row5 col1\" >0.2301</td>\n",
       "      <td id=\"T_31489_row5_col2\" class=\"data row5 col2\" >94.72%</td>\n",
       "      <td id=\"T_31489_row5_col3\" class=\"data row5 col3\" >94.20%</td>\n",
       "      <td id=\"T_31489_row5_col4\" class=\"data row5 col4\" >94.50%</td>\n",
       "      <td id=\"T_31489_row5_col5\" class=\"data row5 col5\" >712.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31489_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_31489_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_31489_row6_col1\" class=\"data row6 col1\" >0.2214</td>\n",
       "      <td id=\"T_31489_row6_col2\" class=\"data row6 col2\" >95.06%</td>\n",
       "      <td id=\"T_31489_row6_col3\" class=\"data row6 col3\" >93.88%</td>\n",
       "      <td id=\"T_31489_row6_col4\" class=\"data row6 col4\" >94.34%</td>\n",
       "      <td id=\"T_31489_row6_col5\" class=\"data row6 col5\" >713.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_31489_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_31489_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_31489_row7_col1\" class=\"data row7 col1\" >0.2156</td>\n",
       "      <td id=\"T_31489_row7_col2\" class=\"data row7 col2\" >95.56%</td>\n",
       "      <td id=\"T_31489_row7_col3\" class=\"data row7 col3\" >94.06%</td>\n",
       "      <td id=\"T_31489_row7_col4\" class=\"data row7 col4\" >94.37%</td>\n",
       "      <td id=\"T_31489_row7_col5\" class=\"data row7 col5\" >712.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1514e09a6a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Summary ---\n",
      "Total epochs run: 8\n",
      "Total training time: 5613.57 seconds\n",
      "\n",
      "Best Validation Accuracy: 94.20% (at Epoch 6)\n",
      "Induced Test Accuracy: 94.50% (at Epoch 6)\n",
      "Best Ever Test Accuracy: 94.50% (at Epoch 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history,  best_induced_test_state = run_roberta_model(\n",
    "    **imdb_data,\n",
    "    epochs=10,        \n",
    "    lr=1e-6,         \n",
    "    batch_size=32,\n",
    "    dropout_rate=0.3,\n",
    "    max_len=512,\n",
    "    patience=2,\n",
    "    device=device,\n",
    ")\n",
    "torch.save( best_induced_test_state, str(config.BEST_ROBERTA_IMDB_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotten Tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_train = pd.read_csv(config.CLEAN_RT_TRAIN_PATH)\n",
    "rt_val = pd.read_csv(config.CLEAN_RT_VAL_PATH)\n",
    "rt_test = pd.read_csv(config.CLEAN_RT_TEST_PATH)\n",
    "\n",
    "rt_x_train = rt_train[config.TEXT_COL]\n",
    "rt_y_train = rt_train[config.LABEL_COL]\n",
    "rt_x_val = rt_val[config.TEXT_COL]\n",
    "rt_y_val = rt_val[config.LABEL_COL]\n",
    "rt_x_test = rt_test[config.TEXT_COL]\n",
    "rt_y_test = rt_test[config.LABEL_COL]\n",
    "rt_data = {\n",
    "    \"x_train\": rt_x_train,\n",
    "    \"y_train\": rt_y_train,\n",
    "    \"x_val\": rt_x_val,\n",
    "    \"y_val\": rt_y_val,\n",
    "    \"x_test\": rt_x_test,\n",
    "    \"y_test\": rt_y_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 10 (no improvement for 2 epochs).\n",
      "--- Epoch History ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_02a4f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_02a4f_level0_col0\" class=\"col_heading level0 col0\" >Epoch</th>\n",
       "      <th id=\"T_02a4f_level0_col1\" class=\"col_heading level0 col1\" >Train Loss</th>\n",
       "      <th id=\"T_02a4f_level0_col2\" class=\"col_heading level0 col2\" >Train Acc</th>\n",
       "      <th id=\"T_02a4f_level0_col3\" class=\"col_heading level0 col3\" >Val Acc</th>\n",
       "      <th id=\"T_02a4f_level0_col4\" class=\"col_heading level0 col4\" >Test Acc</th>\n",
       "      <th id=\"T_02a4f_level0_col5\" class=\"col_heading level0 col5\" >Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_02a4f_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_02a4f_row0_col1\" class=\"data row0 col1\" >0.6861</td>\n",
       "      <td id=\"T_02a4f_row0_col2\" class=\"data row0 col2\" >57.75%</td>\n",
       "      <td id=\"T_02a4f_row0_col3\" class=\"data row0 col3\" >79.73%</td>\n",
       "      <td id=\"T_02a4f_row0_col4\" class=\"data row0 col4\" >79.64%</td>\n",
       "      <td id=\"T_02a4f_row0_col5\" class=\"data row0 col5\" >46.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_02a4f_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_02a4f_row1_col1\" class=\"data row1 col1\" >0.4321</td>\n",
       "      <td id=\"T_02a4f_row1_col2\" class=\"data row1 col2\" >83.72%</td>\n",
       "      <td id=\"T_02a4f_row1_col3\" class=\"data row1 col3\" >86.86%</td>\n",
       "      <td id=\"T_02a4f_row1_col4\" class=\"data row1 col4\" >86.03%</td>\n",
       "      <td id=\"T_02a4f_row1_col5\" class=\"data row1 col5\" >52.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_02a4f_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_02a4f_row2_col1\" class=\"data row2 col1\" >0.3631</td>\n",
       "      <td id=\"T_02a4f_row2_col2\" class=\"data row2 col2\" >86.82%</td>\n",
       "      <td id=\"T_02a4f_row2_col3\" class=\"data row2 col3\" >87.75%</td>\n",
       "      <td id=\"T_02a4f_row2_col4\" class=\"data row2 col4\" >86.50%</td>\n",
       "      <td id=\"T_02a4f_row2_col5\" class=\"data row2 col5\" >44.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_02a4f_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_02a4f_row3_col1\" class=\"data row3 col1\" >0.3422</td>\n",
       "      <td id=\"T_02a4f_row3_col2\" class=\"data row3 col2\" >88.74%</td>\n",
       "      <td id=\"T_02a4f_row3_col3\" class=\"data row3 col3\" >87.75%</td>\n",
       "      <td id=\"T_02a4f_row3_col4\" class=\"data row3 col4\" >86.75%</td>\n",
       "      <td id=\"T_02a4f_row3_col5\" class=\"data row3 col5\" >45.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_02a4f_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_02a4f_row4_col1\" class=\"data row4 col1\" >0.3249</td>\n",
       "      <td id=\"T_02a4f_row4_col2\" class=\"data row4 col2\" >89.54%</td>\n",
       "      <td id=\"T_02a4f_row4_col3\" class=\"data row4 col3\" >88.86%</td>\n",
       "      <td id=\"T_02a4f_row4_col4\" class=\"data row4 col4\" >86.72%</td>\n",
       "      <td id=\"T_02a4f_row4_col5\" class=\"data row4 col5\" >48.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_02a4f_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_02a4f_row5_col1\" class=\"data row5 col1\" >0.3098</td>\n",
       "      <td id=\"T_02a4f_row5_col2\" class=\"data row5 col2\" >89.91%</td>\n",
       "      <td id=\"T_02a4f_row5_col3\" class=\"data row5 col3\" >89.09%</td>\n",
       "      <td id=\"T_02a4f_row5_col4\" class=\"data row5 col4\" >87.38%</td>\n",
       "      <td id=\"T_02a4f_row5_col5\" class=\"data row5 col5\" >48.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_02a4f_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_02a4f_row6_col1\" class=\"data row6 col1\" >0.2950</td>\n",
       "      <td id=\"T_02a4f_row6_col2\" class=\"data row6 col2\" >90.79%</td>\n",
       "      <td id=\"T_02a4f_row6_col3\" class=\"data row6 col3\" >89.09%</td>\n",
       "      <td id=\"T_02a4f_row6_col4\" class=\"data row6 col4\" >87.41%</td>\n",
       "      <td id=\"T_02a4f_row6_col5\" class=\"data row6 col5\" >43.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_02a4f_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_02a4f_row7_col1\" class=\"data row7 col1\" >0.2862</td>\n",
       "      <td id=\"T_02a4f_row7_col2\" class=\"data row7 col2\" >91.51%</td>\n",
       "      <td id=\"T_02a4f_row7_col3\" class=\"data row7 col3\" >89.98%</td>\n",
       "      <td id=\"T_02a4f_row7_col4\" class=\"data row7 col4\" >87.26%</td>\n",
       "      <td id=\"T_02a4f_row7_col5\" class=\"data row7 col5\" >46.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_02a4f_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_02a4f_row8_col1\" class=\"data row8 col1\" >0.2748</td>\n",
       "      <td id=\"T_02a4f_row8_col2\" class=\"data row8 col2\" >92.48%</td>\n",
       "      <td id=\"T_02a4f_row8_col3\" class=\"data row8 col3\" >89.31%</td>\n",
       "      <td id=\"T_02a4f_row8_col4\" class=\"data row8 col4\" >87.32%</td>\n",
       "      <td id=\"T_02a4f_row8_col5\" class=\"data row8 col5\" >50.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02a4f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_02a4f_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_02a4f_row9_col1\" class=\"data row9 col1\" >0.2612</td>\n",
       "      <td id=\"T_02a4f_row9_col2\" class=\"data row9 col2\" >92.96%</td>\n",
       "      <td id=\"T_02a4f_row9_col3\" class=\"data row9 col3\" >89.31%</td>\n",
       "      <td id=\"T_02a4f_row9_col4\" class=\"data row9 col4\" >87.19%</td>\n",
       "      <td id=\"T_02a4f_row9_col5\" class=\"data row9 col5\" >46.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14cf358ce0a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Summary ---\n",
      "Total epochs run: 10\n",
      "Total training time: 473.15 seconds\n",
      "\n",
      "Best Validation Accuracy: 89.98% (at Epoch 8)\n",
      "Induced Test Accuracy: 87.26% (at Epoch 8)\n",
      "Best Ever Test Accuracy: 87.41% (at Epoch 7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history, best_induced_test_state= run_roberta_model(\n",
    "    **rt_data,\n",
    "    epochs=15,        \n",
    "    lr=1e-6,         \n",
    "    batch_size=16,\n",
    "    dropout_rate=0.3,\n",
    "    max_len=50,\n",
    "    patience=2,\n",
    "    device=device,\n",
    ")\n",
    "torch.save( best_induced_test_state, config.BEST_ROBERTA_RT_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
